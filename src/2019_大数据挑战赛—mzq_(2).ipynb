{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "CA7417FD60F940689E9312CC02764F95",
    "scrolled": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!ls -lh /home/kesci/input/bytedance/first-round/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63A92DB6DB5B474396E0B08B0B6774E8",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    "# 基于Tfidf 的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "61F38248ACC4448DAC49113906EEB2CD",
    "scrolled": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from itertools import islice\n",
    "import pdb\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "82881E8D35354108A55A9A5D280D00B2",
    "scrolled": false,
    "hide_input": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "root = '/home/kesci/input/bytedance/first-round/'\n",
    "file_train = 'train.csv'\n",
    "file_test = 'test.csv'\n",
    "path = os.path.join(root, file_train)\n",
    "sql_max_length = 100\n",
    "train_scale = 10000\n",
    "valid_scale = 5000\n",
    "\n",
    "data = {}\n",
    "for k, length in zip(['train','valid'], [train_scale, valid_scale]):\n",
    "    data[k] = {}\n",
    "    for i in ['query','title']:\n",
    "        data[k][i] = np.zeros((length, sql_max_length))\n",
    "    data[k]['label'] = np.zeros((length,))\n",
    "\n",
    "with open(path,'r') as myfile:\n",
    "    lines = csv.reader(myfile)\n",
    "    for index, line in enumerate(islice(lines, 0, train_scale)):\n",
    "        for i,j in zip(['query','title'],[1,3]):\n",
    "            info = np.array(list(map(int, line[j].split())))\n",
    "            length = min(len(info),sql_max_length)\n",
    "            data['train'][i][index,0:length] = info[0:length]\n",
    "        data['train']['label'][index] = int(line[4])\n",
    "            \n",
    "    for index, line in enumerate(islice(lines, train_scale, valid_scale+train_scale)):\n",
    "        for i,j in zip(['query','title'],[1,3]):\n",
    "            info = np.array(list(map(int, line[j].split())))\n",
    "            length = min(len(info),sql_max_length)\n",
    "            data['valid'][i][index,0:length] = info[0:length]\n",
    "        data['valid']['label'][index] = int(line[4])\n",
    "            \n",
    "# 做了padding 和 truncating， 返回固定长度（100）的sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F27D955E5C34B7A99E595EB0681377B",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    "## Tfidf + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "259D35C3941C44D7869B494DD9DC72BD",
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "83f01991-9425-439c-ffe3-9eb15b675281"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-75b889bfd958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m vectorizer_2.fit(list(map(str,np.concatenate((data['train']['query'],data['train']['title'],\n\u001b[1;32m      3\u001b[0m                 data['valid']['query'],data['valid']['title']),axis=0))))\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "vectorizer_2 = TfidfVectorizer()\r\n",
    "vectorizer_2.fit(list(map(str,np.concatenate((data['train']['query'],data['train']['title'],\r\n",
    "                data['valid']['query'],data['valid']['title']),axis=0))))\r\n",
    "tfidf ={}\r\n",
    "for j in ['train','valid']:\r\n",
    "    tfidf[j] = {}\r\n",
    "    for i in ['query','title']:\r\n",
    "        tfidf[j][i] = vectorizer_2.transform(data[j][i]).toarray()\r\n",
    "    tfidf[j]['label'] = np.array(data[j]['label'])\r\n",
    "    tfidf[j]['input'] = np.concatenate(( tfidf[j]['query'],\r\n",
    "        tfidf[j]['query'] - tfidf[j]['title'], \r\n",
    "        tfidf[j]['title']),\r\n",
    "            axis=1, out=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "242ADD55C7C2478A9ED05E2D69284575",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    "|实验记录\t\t\t\t\t\t\t\t\t\t\t      \t|\t\t测试集5000个 | 测试集10000个 内存20G|训练集15000，测试5000\n",
    "|-------------------------------------|----------------|----------------|--------|\n",
    "|当input由query，query-title，title组成，|acc= 0.7372 \t\t\t|\t\t\t0.7403 |  0.7408|\n",
    "|当input由query，query-title组成，\t\t\t|  acc= 0.7434|\n",
    "|当input由query，title组成，\t\t\t\t\t\t|\tacc=0.7468|\n",
    "|当input只由title组成，\t\t\t\t\t\t\t\t|\tacc= 0.748|\n",
    "|当input由query组成，\t\t\t\t\t\t\t\t|\t\tacc= 0.7484|\n",
    "|使用linear SVC                      |    acc = 0.6466         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "D738D13C24F444818CD8947A7CF2E6C8",
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "181cc92d-6411-4b91-da97-fe9be9bb98d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit success!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr = LinearSVC()\n",
    "lr.fit(tfidf['train']['input'], tfidf['train']['label'])\n",
    "print('fit success!')\n",
    "y_pred = lr.predict(tfidf['valid']['input'])\n",
    "acc = np.sum(y_pred == tfidf['valid']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "E5A7563B93244AFDAE2CA93865AFDA6F",
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "9a7299a8-a4e1-4449-baff-86272715e56e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6576\n"
     ]
    }
   ],
   "source": [
    "acc = (np.sum(y_pred == tfidf['valid']['label']))/len(tfidf['valid']['label'])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "948D0207407F41B29423264F4640DC0C",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "9729287E461F40FF97555832F1413D69",
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "e5eb35e0-3447-42f1-a67f-548582eb06be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "BB1810613BF24EC487AD86CDA29233BD",
    "collapsed": true,
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "3480c097-ce55-42f3-ae39-dfe4d64e6bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 0\n",
      " 0loss= 0.710717499256134 running_acc= tensor(17)\n",
      " 3loss= 0.5334789156913757 running_acc= tensor(82)\n",
      " 6loss= 0.6626279950141907 running_acc= tensor(148)\n",
      " 9loss= 0.7817811965942383 running_acc= tensor(212)\n",
      " 12loss= 0.6612915992736816 running_acc= tensor(284)\n",
      " 15loss= 0.8996951580047607 running_acc= tensor(352)\n",
      " 18loss= 0.6115809679031372 running_acc= tensor(422)\n",
      " 21loss= 0.6222792863845825 running_acc= tensor(486)\n",
      " 24loss= 0.7421039342880249 running_acc= tensor(552)\n",
      " 27loss= 0.795581042766571 running_acc= tensor(619)\n",
      " 30loss= 0.8161972165107727 running_acc= tensor(684)\n",
      " 33loss= 0.5987482070922852 running_acc= tensor(759)\n",
      " 36loss= 0.6253782510757446 running_acc= tensor(830)\n",
      " 39loss= 0.6437889337539673 running_acc= tensor(901)\n",
      " 42loss= 0.5909598469734192 running_acc= tensor(972)\n",
      " 45loss= 0.7640033960342407 running_acc= tensor(1027)\n",
      " 48loss= 0.5679319500923157 running_acc= tensor(1094)\n",
      " 51loss= 0.6361846923828125 running_acc= tensor(1165)\n",
      " 54loss= 0.6828713417053223 running_acc= tensor(1243)\n",
      " 57loss= 0.5238448977470398 running_acc= tensor(1320)\n",
      " 60loss= 0.6565902829170227 running_acc= tensor(1386)\n",
      " 63loss= 0.7912271022796631 running_acc= tensor(1447)\n",
      " 66loss= 0.4354376494884491 running_acc= tensor(1512)\n",
      " 69loss= 0.8446729779243469 running_acc= tensor(1580)\n",
      " 72loss= 0.6152724027633667 running_acc= tensor(1659)\n",
      " 75loss= 0.5487117767333984 running_acc= tensor(1733)\n",
      " 78loss= 0.6002539992332458 running_acc= tensor(1801)\n",
      " 81loss= 0.5113181471824646 running_acc= tensor(1869)\n",
      " 84loss= 0.37997135519981384 running_acc= tensor(1948)\n",
      " 87loss= 0.7032998204231262 running_acc= tensor(2019)\n",
      " 90loss= 0.4971652626991272 running_acc= tensor(2094)\n",
      " 93loss= 0.5119867324829102 running_acc= tensor(2165)\n",
      " 96loss= 0.5071197748184204 running_acc= tensor(2238)\n",
      " 99loss= 0.7500991821289062 running_acc= tensor(2306)\n",
      " 102loss= 0.4787946939468384 running_acc= tensor(2374)\n",
      " 105loss= 0.5908976793289185 running_acc= tensor(2440)\n",
      " 108loss= 0.6734033823013306 running_acc= tensor(2507)\n",
      " 111loss= 0.6058950424194336 running_acc= tensor(2579)\n",
      " 114loss= 0.5220276713371277 running_acc= tensor(2653)\n",
      " 117loss= 0.6460702419281006 running_acc= tensor(2721)\n",
      " 120loss= 0.5617123246192932 running_acc= tensor(2796)\n",
      " 123loss= 0.9379982948303223 running_acc= tensor(2851)\n",
      " 126loss= 0.6861602067947388 running_acc= tensor(2907)\n",
      " 129loss= 0.5403788089752197 running_acc= tensor(2969)\n",
      " 132loss= 0.5657123923301697 running_acc= tensor(3041)\n",
      " 135loss= 0.45304930210113525 running_acc= tensor(3121)\n",
      " 138loss= 0.8973402976989746 running_acc= tensor(3192)\n",
      " 141loss= 0.6462722420692444 running_acc= tensor(3260)\n",
      " 144loss= 0.7363768219947815 running_acc= tensor(3321)\n",
      " 147loss= 0.5904302000999451 running_acc= tensor(3389)\n",
      " 150loss= 0.8276156783103943 running_acc= tensor(3463)\n",
      " 153loss= 0.4654872417449951 running_acc= tensor(3548)\n",
      " 156loss= 0.6910395622253418 running_acc= tensor(3617)\n",
      " 159loss= 0.6789875030517578 running_acc= tensor(3676)\n",
      " 162loss= 0.8906979560852051 running_acc= tensor(3718)\n",
      " 165loss= 0.6047353148460388 running_acc= tensor(3780)\n",
      " 168loss= 0.832425057888031 running_acc= tensor(3843)\n",
      " 171loss= 0.6390236020088196 running_acc= tensor(3910)\n",
      " 174loss= 0.5361415147781372 running_acc= tensor(3992)\n",
      " 177loss= 0.38348498940467834 running_acc= tensor(4072)\n",
      " 180loss= 0.9485260844230652 running_acc= tensor(4130)\n",
      " 183loss= 0.5047564506530762 running_acc= tensor(4208)\n",
      " 186loss= 0.7048674821853638 running_acc= tensor(4273)\n",
      " 189loss= 0.42382287979125977 running_acc= tensor(4347)\n",
      " 192loss= 0.6458737254142761 running_acc= tensor(4416)\n",
      " 195loss= 0.6028077602386475 running_acc= tensor(4492)\n",
      " 198loss= 0.5137403011322021 running_acc= tensor(4567)\n",
      " 199"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f077a0d6aa9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'running_acc='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# batch_size = 32\r\n",
    "# def get_data(step, data, batch_size):\r\n",
    "#     querys = torch.tensor(data['query'][step*batch_size:step*batch_size+batch_size], dtype=torch.long)\r\n",
    "#     titles = torch.tensor(data['title'][step*batch_size:step*batch_size+batch_size],dtype=torch.long)\r\n",
    "#     labels = torch.tensor(data['label'][step*batch_size:step*batch_size+batch_size],dtype=torch.long)\r\n",
    "#     inputs = torch.cat((querys, titles), dim=1)\r\n",
    "#     return inputs, labels\r\n",
    "    \r\n",
    "    \r\n",
    "# for epoch in range(num_epoch):\r\n",
    "#     print()\r\n",
    "#     print('epoch:',epoch)\r\n",
    "#     total_loss = 0\r\n",
    "#     running_acc = 0.0\r\n",
    "#     valid_acc = 0.0\r\n",
    "#     model.train()\r\n",
    "#     for step in range(int(data['train']['query'].shape[0] / batch_size)):\r\n",
    "#         print('\\r', step, end='')\r\n",
    "#         inputs, labels = get_data(step, data['train'], batch_size)\r\n",
    "#         #pdb.set_trace()\r\n",
    "#         model.zero_grad()\r\n",
    "#         outputs = model(inputs) # log_probs = 1 * 23046, embeds = 1*60\r\n",
    "#         #pdb.set_trace()\r\n",
    "#         loss = loss_function(outputs, labels)\r\n",
    "#         total_loss += loss.item()\r\n",
    "#         _, pred = torch.max(outputs,1)\r\n",
    "#         running_acc += torch.sum(pred.data == labels.data)\r\n",
    "#         if step%3 == 0:\r\n",
    "#             print('loss=',loss.item(),'running_acc=',running_acc.item())\r\n",
    "#         loss.backward()\r\n",
    "#         optimizer.step()\r\n",
    "#     train_acc = running_acc.double()/len(step*batch_size)\r\n",
    "    \r\n",
    "#     running_acc = 0.0\r\n",
    "#     for step, batch in enumerate(iter(valid_iter)):\r\n",
    "#         print('\\r', step, end='')\r\n",
    "#         model.eval()\r\n",
    "#         inputs = batch.review.to(device)  # 100 * 16\r\n",
    "#         targets = batch.label_binary.to(device) # 16\r\n",
    "#         inputs = inputs.unsqueeze(2) # 100 * 16 * 1\r\n",
    "#         inputs = inputs.permute(1,2,0)\r\n",
    "                \r\n",
    "#         model.zero_grad()\r\n",
    "        \r\n",
    "#         outputs = model(inputs) # log_probs = 1 * 23046, embeds = 1*60\r\n",
    "#         #pdb.set_trace()\r\n",
    "                \r\n",
    "#         #loss = loss_function(outputs, targets)\r\n",
    "#         #total_loss += loss.item()\r\n",
    "        \r\n",
    "#         _, pred = torch.max(outputs,1)\r\n",
    "#         running_acc += torch.sum(pred == targets.data)\r\n",
    "        \r\n",
    "#     valid_acc = running_acc.double()/len(valid.examples)    \r\n",
    "\r\n",
    "    \r\n",
    "#     losses.append(total_loss)\r\n",
    "#     print('epoch={} total_loss={:.4f} train_acc={:.4f} valid_acc={:.4f}'.format(epoch, total_loss, train_acc, valid_acc))\r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3332AF623C944C3B66534C0967F7335",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    "# RNN attention + CNN 2019/05/30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FE4015422697409982A39186F3D7AA33",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    "### 建立词向量 fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKVebPPmrHyG",
    "colab_type": "text"
   },
   "source": [
    "### 安装fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KpxmZbYxsRpD",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227.0
    },
    "outputId": "753ca406-7206-44f8-cbba-27024855c164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'fastText' already exists and is not an empty directory.\n",
      "Processing /content/fastText\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.8.22) (2.2.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.8.22) (41.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.8.22) (1.16.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-aib6eb96/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.8.22\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!git clone https://github.com/facebookresearch/fastText.git\n",
    "os.chdir('fastText')\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D72840E4884644D086307EE9114DF89F",
    "scrolled": false,
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "6338a451-81ed-43c6-df2e-07ff25333895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastText  sample_data\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from itertools import islice\n",
    "import pdb\n",
    "import torch\n",
    "os.chdir('/content/')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F967BD59A3C1442488A5957446C8111C",
    "scrolled": false,
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69.0
    },
    "outputId": "92903b56-004d-493f-bb2e-43608424a423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 0: syntax error near unexpected token `..'\n",
      "/bin/bash: -c: line 0: `os.chdir(..)'\n",
      "Processed 10001 lines.\n"
     ]
    }
   ],
   "source": [
    "import fastText\n",
    "!os.chdir(..)\n",
    "import csv\n",
    "with open('sample_train.txt', 'w') as f:\n",
    "    #with open('../input/bytedance/first-round/train.csv') as csv_file:\n",
    "    with open('train_data.sample') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            query = row[1]\n",
    "            title = row[3]\n",
    "            label = row[4]\n",
    "            line_count+=1\n",
    "            f.write(\"__label__{0} {1} {2}\\n\".format(label, query, title))\n",
    "            if line_count > 1*10000: # 10000*10000 一亿条要一晚上\n",
    "                break\n",
    "            if line_count% 1e6 == 0:\n",
    "                print(line_count/1e6,'百万')\n",
    "        print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0D312633C72A4CC7BFEC24259E2BE3C8",
    "scrolled": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#!head -n 5 labeled_content\r\n",
    "!head -n 9000 train10000 > train9000.txt\r\n",
    "!tail -n 1000 train10000 > valid1000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5C854CF9AF36493FB3944B18D4479F67",
    "scrolled": false,
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "62c8ec79-bbfc-42b8-8951-84ec14e2519b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.967702150344849\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "model = fastText.train_supervised(\n",
    "   input = \"sample_train.txt\", epoch=25, lr=0.1, wordNgrams=2, verbose=2, minCount=1\n",
    ")\n",
    "print(time.time()-since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "313F7B595848490B95F01B06B5F94BA2",
    "scrolled": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "result = model.test('valid.txt')\n",
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "print_results(*result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "28C42FEEDA494825AE10AF2BC36FC491",
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "11c418ea-71ab-46f8-82ba-b694fb45cd86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(model.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "EC09545CAF2F496C9000C95B085A6F25",
    "scrolled": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model.save_model(\"model.bin\")\n",
    "#loaded_model = fastText.load_model(\"model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EDF9CA5CEA44A698D20D9B7F1EB2778",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "9CABBB17CEFD43838071B0061F61CE10",
    "collapsed": true,
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "4aac8359-2819-44fe-fca0-5f2d9752fd08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023885, 100)\n",
      "(2, 100)\n",
      "23885\n",
      "[-0.00857826 -0.0582859   0.00541913  0.02087143 -0.02704096 -0.04855686\n",
      "  0.06261121  0.00428706 -0.05668503 -0.03571691  0.05362597 -0.03948804\n",
      " -0.01707815 -0.0379849   0.05985313  0.01122388 -0.04075426 -0.01043027\n",
      "  0.00387146  0.01628842 -0.01686643 -0.08128726 -0.04844168 -0.00448627\n",
      " -0.00934992  0.03206352 -0.00831332  0.06307277  0.03714691 -0.06296124\n",
      "  0.0523917   0.00318891  0.04823148  0.02991723  0.0330345   0.00944853\n",
      "  0.0168553  -0.00531108  0.01428792  0.0050365   0.00751749 -0.02754628\n",
      " -0.00047341 -0.00502049 -0.01116158  0.00715705 -0.00992763  0.01465497\n",
      "  0.05383023 -0.02920387  0.03051862 -0.03568185  0.04135505 -0.03021663\n",
      "  0.0280046   0.01603298  0.02707767 -0.00818382 -0.03789839 -0.04211527\n",
      "  0.01543094 -0.05493718 -0.03773625 -0.04500303  0.01163789  0.00681081\n",
      "  0.04258104 -0.02358605 -0.01216784 -0.02581844  0.02962485 -0.00083301\n",
      " -0.03062108  0.02632382  0.02813586 -0.00693136 -0.05490098 -0.01260491\n",
      " -0.0454154   0.00569126 -0.00600953 -0.00442117 -0.03864931  0.02872271\n",
      " -0.0102388   0.03757674  0.00388457 -0.0064219   0.03520627 -0.00160695\n",
      " -0.04042048 -0.03394781 -0.07791369  0.03286719 -0.0166983   0.03171569\n",
      "  0.00533371 -0.04924375  0.03450744  0.01312162]\n",
      "id 7\n",
      "22+22= [-0.00384928  0.05530865 -0.01873369 -0.03150985  0.0246413   0.02416458\n",
      " -0.03707929  0.00134349  0.01066456  0.00495567 -0.00569841  0.00187864\n",
      "  0.00283754 -0.00209243  0.01010812  0.00151461 -0.00542044  0.00139636\n",
      " -0.00046297  0.00472488 -0.00475262 -0.01911545 -0.01400516 -0.00304326\n",
      " -0.00357242  0.00481476 -0.00472347  0.01300984  0.02083954 -0.03026581\n",
      "  0.02331018 -0.00062815  0.00927578  0.00319306  0.00182188  0.00433694\n",
      " -0.00153844 -0.00482475  0.00096745 -0.0015768   0.00555345 -0.00374965\n",
      " -0.00374134  0.0031257   0.04852813 -0.00320863  0.0529131  -0.01646921\n",
      " -0.06858356  0.06417733 -0.06007364  0.05309151 -0.04090367  0.04895918\n",
      " -0.03164503 -0.0210242  -0.03358921  0.01305774  0.05976302  0.04221443\n",
      "  0.00797155 -0.02936358 -0.02391532 -0.0213604  -0.0024307  -0.00241811\n",
      "  0.00274014 -0.00213065 -0.00330109 -0.00467935  0.00347616  0.00118442\n",
      " -0.00415607  0.00250409  0.00160822  0.00347207 -0.00842271 -0.00075244\n",
      " -0.01267883 -0.00296228  0.0006522   0.00091482  0.00092124  0.00546262\n",
      "  0.00126001  0.00833486 -0.00010748  0.001505    0.00192819 -0.00091331\n",
      " -0.00182542 -0.005513    0.0561338  -0.0383562   0.00117088 -0.0386679\n",
      " -0.01601545  0.06798398 -0.04843044 -0.02897643]\n"
     ]
    }
   ],
   "source": [
    "print(model.get_input_matrix().shape)\n",
    "print(model.get_output_matrix().shape)\n",
    "print(len(model.get_words()))\n",
    "print(model.get_word_vector('22'))\n",
    "#print(model.get_word_vector('23'))\n",
    "print('id',model.get_word_id('22'))\n",
    "#print(model.get_input_matrix()[7])\n",
    "print('22+22=',model.get_sentence_vector('22 22'))\n",
    "#print(model.get_sentence_vector('22 23'))\n",
    "#print(model.get_sentence_vector('22 34343 3434345645324').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4B1F405EC7DB49398401AB75AB073B4D",
    "collapsed": true,
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "97b8ffa1-f8a4-4603-d104-f800ea545e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _FastText in module fastText.FastText object:\n",
      "\n",
      "class _FastText(builtins.object)\n",
      " |  This class defines the API to inspect models and should not be used to\n",
      " |  create objects. It will be returned by functions such as load_model or\n",
      " |  train.\n",
      " |  \n",
      " |  In general this API assumes to be given only unicode for Python2 and the\n",
      " |  Python3 equvalent called str for any string-like arguments. All unicode\n",
      " |  strings are then encoded as UTF-8 and fed to the fastText C++ API.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_dimension(self)\n",
      " |      Get the dimension (size) of a lookup vector (hidden layer).\n",
      " |  \n",
      " |  get_input_matrix(self)\n",
      " |      Get a copy of the full input matrix of a Model. This only\n",
      " |      works if the model is not quantized.\n",
      " |  \n",
      " |  get_input_vector(self, ind)\n",
      " |      Given an index, get the corresponding vector of the Input Matrix.\n",
      " |  \n",
      " |  get_labels(self, include_freq=False)\n",
      " |      Get the entire list of labels of the dictionary optionally\n",
      " |      including the frequency of the individual labels. Unsupervised\n",
      " |      models use words as labels, which is why get_labels\n",
      " |      will call and return get_words for this type of\n",
      " |      model.\n",
      " |  \n",
      " |  get_line(self, text)\n",
      " |      Split a line of text into words and labels. Labels must start with\n",
      " |      the prefix used to create the model (__label__ by default).\n",
      " |  \n",
      " |  get_output_matrix(self)\n",
      " |      Get a copy of the full output matrix of a Model. This only\n",
      " |      works if the model is not quantized.\n",
      " |  \n",
      " |  get_sentence_vector(self, text)\n",
      " |      Given a string, get a single vector represenation. This function\n",
      " |      assumes to be given a single line of text. We split words on\n",
      " |      whitespace (space, newline, tab, vertical tab) and the control\n",
      " |      characters carriage return, formfeed and the null character.\n",
      " |  \n",
      " |  get_subword_id(self, subword)\n",
      " |      Given a subword, return the index (within input matrix) it hashes to.\n",
      " |  \n",
      " |  get_subwords(self, word)\n",
      " |      Given a word, get the subwords and their indicies.\n",
      " |  \n",
      " |  get_word_id(self, word)\n",
      " |      Given a word, get the word id within the dictionary.\n",
      " |      Returns -1 if word is not in the dictionary.\n",
      " |  \n",
      " |  get_word_vector(self, word)\n",
      " |      Get the vector representation of word.\n",
      " |  \n",
      " |  get_words(self, include_freq=False)\n",
      " |      Get the entire list of words of the dictionary optionally\n",
      " |      including the frequency of the individual words. This\n",
      " |      does not include any subwords. For that please consult\n",
      " |      the function get_subwords.\n",
      " |  \n",
      " |  is_quantized(self)\n",
      " |  \n",
      " |  predict(self, text, k=1, threshold=0.0)\n",
      " |      Given a string, get a list of labels and a list of\n",
      " |      corresponding probabilities. k controls the number\n",
      " |      of returned labels. A choice of 5, will return the 5\n",
      " |      most probable labels. By default this returns only\n",
      " |      the most likely label and probability. threshold filters\n",
      " |      the returned labels by a threshold on probability. A\n",
      " |      choice of 0.5 will return labels with at least 0.5\n",
      " |      probability. k and threshold will be applied together to\n",
      " |      determine the returned labels.\n",
      " |      \n",
      " |      This function assumes to be given\n",
      " |      a single line of text. We split words on whitespace (space,\n",
      " |      newline, tab, vertical tab) and the control characters carriage\n",
      " |      return, formfeed and the null character.\n",
      " |      \n",
      " |      If the model is not supervised, this function will throw a ValueError.\n",
      " |      \n",
      " |      If given a list of strings, it will return a list of results as usually\n",
      " |      received for a single line of text.\n",
      " |  \n",
      " |  quantize(self, input=None, qout=False, cutoff=0, retrain=False, epoch=None, lr=None, thread=None, verbose=None, dsub=2, qnorm=False)\n",
      " |      Quantize the model reducing the size of the model and\n",
      " |      it's memory footprint.\n",
      " |  \n",
      " |  save_model(self, path)\n",
      " |      Save the model to the given path\n",
      " |  \n",
      " |  test(self, path, k=1)\n",
      " |      Evaluate supervised model using file given by path\n",
      " |  \n",
      " |  test_label(self, path, k=1, threshold=0.0)\n",
      " |      Return the precision and recall score for each label.\n",
      " |      \n",
      " |      The returned value is a dictionary, where the key is the label.\n",
      " |      For example:\n",
      " |      f.test_label(...)\n",
      " |      {'__label__italian-cuisine' : {'precision' : 0.7, 'recall' : 0.74}}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D52D9ABBE524CFCB3984E7219DA89B4",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    "## 定义了MyDataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6050FCF5688A4A9ABDD44C2D3BB41C05",
    "scrolled": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class MyDataloader(object):\n",
    "    def __init__(self, model, batch_size=32):\n",
    "        self.task_name = 'train'\n",
    "        self.file = None\n",
    "        self.max_sql = 50\n",
    "        self.batch_size= batch_size\n",
    "#         self.train_file = '/home/kesci/input/bytedance/first-round/train.csv'\n",
    "#         self.test_file = '/home/kesci/input/bytedance/first-round/test.csv'\n",
    "        self.train_file = 'sample_train.csv'\n",
    "        self.test_file = 'sample_test.csv'\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "    def convert(self, line):\n",
    "        query = torch.zeros((self.max_sql,1,100)) # 词向量长度为100\n",
    "        #pdb.set_trace()\n",
    "        for index, word in enumerate(islice(line[1].split(),0,self.max_sql)):\n",
    "            query[index,0,:] = torch.tensor(model.get_word_vector(word))\n",
    "            \n",
    "        title = torch.zeros((self.max_sql,1,100)) # 词向量长度为100 [60*1*100]\n",
    "        for index, word in enumerate(islice(line[3].split(),0,self.max_sql)):\n",
    "            title[index,0,:] = torch.tensor(model.get_word_vector(word))\n",
    "        \n",
    "        try:\n",
    "            label = torch.tensor(int(line[4]), dtype=torch.long)\n",
    "        except:\n",
    "            label = 0\n",
    "            \n",
    "        return query, title, label\n",
    "        \n",
    "    def set_train(self):\n",
    "        self.task_name = 'train'\n",
    "        f = open(self.train_file,'r')\n",
    "        self.lines = csv.reader(f)\n",
    "    \n",
    "    def set_valid(self):\n",
    "        self.task_name = 'valid'\n",
    "        f = open(self.train_file,'r')\n",
    "        self.lines = csv.reader(f)\n",
    "        \n",
    "    def set_test(self):\n",
    "        self.task_name = 'test'\n",
    "        f = open(self.test_file,'r')\n",
    "        self.lines = csv.reader(f)\n",
    "    \n",
    "    def get_data(self):\n",
    "        data = {}\n",
    "        data['query'] = torch.zeros((self.max_sql, self.batch_size,100)) \n",
    "        data['title'] = torch.zeros((self.max_sql, self.batch_size,100)) \n",
    "        data['label'] = torch.zeros((self.batch_size), dtype=torch.long) # [1 * 32 * 1] \n",
    "        for step in range(0, self.batch_size):\n",
    "            line = next(self.lines)\n",
    "            query, title, label = self.convert(line)\n",
    "            #pdb.set_trace()\n",
    "            data['query'][:,step,:] = torch.squeeze(query)\n",
    "            data['title'][:,step,:] = torch.squeeze(title)\n",
    "            data['label'][step] = label\n",
    "        return data\n",
    "batch_size = 32\n",
    "data_loader = MyDataloader(model, batch_size=batch_size)\n",
    "data_loader.set_train()\n",
    "data = data_loader.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "AC05E42820A745F488F24F7EDC711752",
    "scrolled": false,
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86.0
    },
    "outputId": "30a3e90f-f81c-45c3-8609-fdc4ef75d5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 32, 100])\n",
      "torch.Size([50, 32, 100])\n",
      "torch.Size([32])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    print(data[item].shape)\n",
    "print(data['label'][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ED8ABFD7EAC4C7884F2001BFF15CFD5",
    "mdEditEnable": false,
    "colab_type": "text"
   },
   "source": [
    "### RNN + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "75E79A74E3414DC8A0A430083D0B99AA",
    "scrolled": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ninput=100, nhid=32, nlayers=4, LSTM=False, ATTEN=False, DOUBLE=True):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.model_name = 'RNN'\n",
    "        self.double = DOUBLE\n",
    "        #self.encoder = nn.Embedding(nvoc, ninput)\n",
    "        # WRITE CODE HERE witnin two '#' bar\n",
    "        ########################################\n",
    "        # Construct you RNN model here. You can add additional parameters to the function.\n",
    "        if LSTM:\n",
    "            print('model is a LSTM model')\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=ninput,\n",
    "                hidden_size=nhid,\n",
    "                num_layers=nlayers,\n",
    "                batch_first=False\n",
    "            )\n",
    "        else:\n",
    "            print('model is a RNN model')\n",
    "            self.rnn = nn.RNN(\n",
    "                input_size=ninput,\n",
    "                hidden_size=nhid,\n",
    "                num_layers=nlayers,\n",
    "                batch_first=False\n",
    "            )\n",
    "\n",
    "        if ATTEN:\n",
    "            pass\n",
    "        ########################################\n",
    "        self.linear = nn.Linear(nhid, 2)\n",
    "        self.cos = nn.CosineSimilarity(dim=0,eps=1e-6)\n",
    "        \n",
    "        #self.init_weights()\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        #print('model is a RNN model')\n",
    "    # def init_weights(self):\n",
    "    #     init_uniform = 0.1\n",
    "    #     self.encoder.weight.data.uniform_(-init_uniform, init_uniform)\n",
    "    #     self.decoder.bias.data.zero_()\n",
    "    #     self.decoder.weight.data.uniform_(-init_uniform, init_uniform)\n",
    "\n",
    "    def forward(self, in1, in2): # input  shape [60,32,100]\n",
    "        drop1 = self.drop(in1) # shape [60, 32, 100]\n",
    "        drop2 = self.drop(in2)\n",
    "        # WRITE CODE HERE within two '#' bar\n",
    "        ########################################\n",
    "        # With embeddings, you can get your output here.\n",
    "        # Output has the dimension of sequence_length * batch_size * number of classes\n",
    "        output1, h_state = self.rnn(drop1, None) # shape [60,32,64], [2,32,64]\n",
    "        output2, h_state = self.rnn(drop2, None)\n",
    "        # r_out [seq, batch, h_dim * 方向 = 64*1]\n",
    "        # h_n = [层数*方向=1*1, batch, h_dim]\n",
    "        cos_distance = - self.cos(output1, output2) # [32,64] 距离越靠近1越好\n",
    "        ########################################\n",
    "\n",
    "        #output = self.drop(output)\n",
    "        out = self.linear(cos_distance)\n",
    "        # shape [700, 10000]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4C070AFBDE5243118FBEC244B2696D31",
    "scrolled": false,
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(2019 )\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, ninput=100, nhid=32, n_out=2, method='1'):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.model_name = 'CNN'\n",
    "        self.method = method\n",
    "        self.activ = nn.Tanh()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        print('this is a CNN net, method=',method)\n",
    "        ########################################################################################\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, nhid,  kernel_size=(5,10), stride=(1,5)),\n",
    "                                   nn.BatchNorm2d(nhid),\n",
    "                                   self.activ)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(nhid, nhid*2, kernel_size=(5,10), stride=(2,5)),\n",
    "                                   nn.BatchNorm2d(nhid*2),\n",
    "                                   self.activ,\n",
    "                                   nn.Dropout2d(0.5))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(nhid*2, nhid*2, kernel_size=(3,2), stride=(2,1)),\n",
    "                                   nn.BatchNorm2d(nhid*2),\n",
    "                                   self.activ)\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=(3,1), stride=1),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  self.activ,\n",
    "                                  nn.Dropout2d(0.5))\n",
    "        self.conv = nn.Sequential(self.conv1,self.conv2,self.conv3,self.conv4)\n",
    "        ##########################################################################################\n",
    "        self.cos = nn.CosineSimilarity(dim=2,eps=1e-6)                           \n",
    "        self.linear1 = nn.Linear(64, 32)                           \n",
    "        self.linear2 = nn.Linear(512, 32)\n",
    "        self.linear_last = nn.Linear(32,n_out)\n",
    "    def forward(self, in1, in2): # inputs = 30 * 16 * 100   32是batch_size\n",
    "        if self.method == '1':\n",
    "            in1 = torch.unsqueeze(torch.transpose(in1,0,1),1) # 16 1 30 100\n",
    "            in2 = torch.unsqueeze(torch.transpose(in2,0,1),1)\n",
    "            #pdb.set_trace()\n",
    "            out1 =self.conv(in1) # 16 64 4 1\n",
    "            out2 =self.conv(in2)\n",
    "            cos_distance = torch.exp(- self.cos(out1, out2)) # 64 4 1\n",
    "            #pdb.set_trace()\n",
    "            out = self.linear_last(self.relu(self.linear1(cos_distance.squeeze())))\n",
    "        elif self.method == '2':\n",
    "            in1 = torch.unsqueeze(torch.transpose(in1,0,1),1) # 16 1 30 100\n",
    "            in2 = torch.unsqueeze(torch.transpose(in2,0,1),1)\n",
    "            inputs = torch.cat((in1, in2),dim=1)\n",
    "            out = self.conv(inputs)\n",
    "            #pdb.set_trace()\n",
    "            out = out.view(out.size(0),-1)\n",
    "            #pdb.set_trace()\n",
    "            out = self.linear_last(nn.ReLU(self.linear2(out)))\n",
    "#         else:   \n",
    "\n",
    "#             inputs = torch.cat((in1, in2),dim=0)\n",
    "#             out = torch.transpose(inputs, 0, 1)                                #在CNN里，是256*3*64*64\n",
    "#             out = torch.unsqueeze(out, 1) # 16 * 1 * 30 * 100\n",
    "#             #pdb.set_trace()\n",
    "#             out = [F.relu(conv(x)) for conv in self.conv] # 16 * 16 * 28 * 1 \n",
    "#     #         out = self.conv2(out)\n",
    "#     #         out = self.conv3(out)\n",
    "#     #         out = self.conv4(out)  \n",
    "\n",
    "#             out = out.view(out.size(0),-1)\n",
    "#             out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3248Vz0IfwA",
    "colab_type": "text"
   },
   "source": [
    "第一次试验 CNN 100epoch 最高qAUC=0.52 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuBpZBTpoOv6",
    "colab_type": "text"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgY-IwIY8Aum",
    "colab_type": "text"
   },
   "source": [
    "## 训练开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8AF2CA5747154E1788FCBDCB83F9435F",
    "scrolled": false,
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3941.0
    },
    "outputId": "fdf0fbf5-277a-4a38-ec6c-f0e4a5c6e5aa",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a CNN net, method= 1\n",
      "\n",
      "epoch 1 time(m) 0\n",
      " 100 train_loss:0.6479 running_acc:0.7416\n",
      " 200 train_loss:0.6465 running_acc:0.7462\n",
      " 300 train_loss:0.6456 running_acc:0.7470\n",
      " 400 train_loss:0.6452 running_acc:0.7430\n",
      " 500 train_loss:0.6450 running_acc:0.7458\n",
      " 529Saving train_loss:0.6448 train_acc:0.7468 test_qAUC:0.5227\n",
      "model saved!\n",
      "\n",
      "epoch 2 time(m) 2\n",
      " 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CNNModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100 train_loss:0.6443 running_acc:0.7472\n",
      " 200 train_loss:0.6444 running_acc:0.7491\n",
      " 300 train_loss:0.6440 running_acc:0.7489\n",
      " 400 train_loss:0.6440 running_acc:0.7445\n",
      " 500 train_loss:0.6439 running_acc:0.7469\n",
      " 529Saving train_loss:0.6439 train_acc:0.7478 test_qAUC:0.4827\n",
      "\n",
      "epoch 3 time(m) 4\n",
      " 100 train_loss:0.6442 running_acc:0.7472\n",
      " 200 train_loss:0.6438 running_acc:0.7491\n",
      " 300 train_loss:0.6438 running_acc:0.7489\n",
      " 400 train_loss:0.6435 running_acc:0.7445\n",
      " 500 train_loss:0.6436 running_acc:0.7469\n",
      " 529Saving train_loss:0.6437 train_acc:0.7478 test_qAUC:0.4973\n",
      "\n",
      "epoch 4 time(m) 6\n",
      " 100 train_loss:0.6428 running_acc:0.7472\n",
      " 200 train_loss:0.6431 running_acc:0.7491\n",
      " 300 train_loss:0.6435 running_acc:0.7489\n",
      " 400 train_loss:0.6434 running_acc:0.7445\n",
      " 500 train_loss:0.6435 running_acc:0.7469\n",
      " 529Saving train_loss:0.6434 train_acc:0.7478 test_qAUC:0.5084\n",
      "\n",
      "epoch 5 time(m) 8\n",
      " 100 train_loss:0.6439 running_acc:0.7472\n",
      " 200 train_loss:0.6433 running_acc:0.7491\n",
      " 300 train_loss:0.6436 running_acc:0.7489\n",
      " 400 train_loss:0.6433 running_acc:0.7445\n",
      " 500 train_loss:0.6434 running_acc:0.7469\n",
      " 529Saving train_loss:0.6433 train_acc:0.7478 test_qAUC:0.5096\n",
      "\n",
      "epoch 6 time(m) 10\n",
      " 100 train_loss:0.6431 running_acc:0.7472\n",
      " 200 train_loss:0.6429 running_acc:0.7491\n",
      " 300 train_loss:0.6431 running_acc:0.7489\n",
      " 400 train_loss:0.6429 running_acc:0.7445\n",
      " 500 train_loss:0.6430 running_acc:0.7469\n",
      " 529Saving train_loss:0.6429 train_acc:0.7478 test_qAUC:0.5118\n",
      "\n",
      "epoch 7 time(m) 12\n",
      " 100 train_loss:0.6436 running_acc:0.7472\n",
      " 200 train_loss:0.6431 running_acc:0.7491\n",
      " 300 train_loss:0.6434 running_acc:0.7489\n",
      " 400 train_loss:0.6432 running_acc:0.7445\n",
      " 500 train_loss:0.6432 running_acc:0.7469\n",
      " 529Saving train_loss:0.6431 train_acc:0.7478 test_qAUC:0.5039\n",
      "\n",
      "epoch 8 time(m) 14\n",
      " 100 train_loss:0.6428 running_acc:0.7472\n",
      " 200 train_loss:0.6427 running_acc:0.7491\n",
      " 300 train_loss:0.6429 running_acc:0.7489\n",
      " 400 train_loss:0.6430 running_acc:0.7445\n",
      " 500 train_loss:0.6430 running_acc:0.7469\n",
      " 529Saving train_loss:0.6430 train_acc:0.7478 test_qAUC:0.5092\n",
      "\n",
      "epoch 9 time(m) 16\n",
      " 100 train_loss:0.6435 running_acc:0.7472\n",
      " 200 train_loss:0.6424 running_acc:0.7491\n",
      " 300 train_loss:0.6427 running_acc:0.7489\n",
      " 400 train_loss:0.6426 running_acc:0.7445\n",
      " 500 train_loss:0.6424 running_acc:0.7469\n",
      " 529Saving train_loss:0.6425 train_acc:0.7478 test_qAUC:0.4973\n",
      "\n",
      "epoch 10 time(m) 18\n",
      " 100 train_loss:0.6434 running_acc:0.7472\n",
      " 200 train_loss:0.6430 running_acc:0.7491\n",
      " 300 train_loss:0.6434 running_acc:0.7489\n",
      " 400 train_loss:0.6431 running_acc:0.7445\n",
      " 500 train_loss:0.6429 running_acc:0.7469\n",
      " 529Saving train_loss:0.6430 train_acc:0.7478 test_qAUC:0.5238\n",
      "model saved!\n",
      "\n",
      "epoch 11 time(m) 20\n",
      " 100 train_loss:0.6435 running_acc:0.7472\n",
      " 200 train_loss:0.6425 running_acc:0.7491\n",
      " 300 train_loss:0.6428 running_acc:0.7489\n",
      " 400 train_loss:0.6425 running_acc:0.7445\n",
      " 500 train_loss:0.6425 running_acc:0.7469\n",
      " 529Saving train_loss:0.6425 train_acc:0.7478 test_qAUC:0.5072\n",
      "\n",
      "epoch 12 time(m) 22\n",
      " 100 train_loss:0.6436 running_acc:0.7472\n",
      " 200 train_loss:0.6428 running_acc:0.7491\n",
      " 300 train_loss:0.6429 running_acc:0.7489\n",
      " 400 train_loss:0.6428 running_acc:0.7445\n",
      " 500 train_loss:0.6428 running_acc:0.7469\n",
      " 529Saving train_loss:0.6428 train_acc:0.7478 test_qAUC:0.5087\n",
      "\n",
      "epoch 13 time(m) 24\n",
      " 100 train_loss:0.6433 running_acc:0.7472\n",
      " 200 train_loss:0.6430 running_acc:0.7491\n",
      " 300 train_loss:0.6429 running_acc:0.7489\n",
      " 400 train_loss:0.6430 running_acc:0.7445\n",
      " 500 train_loss:0.6431 running_acc:0.7469\n",
      " 529Saving train_loss:0.6431 train_acc:0.7478 test_qAUC:0.4942\n",
      "\n",
      "epoch 14 time(m) 26\n",
      " 100 train_loss:0.6426 running_acc:0.7472\n",
      " 200 train_loss:0.6425 running_acc:0.7491\n",
      " 300 train_loss:0.6429 running_acc:0.7489\n",
      " 400 train_loss:0.6429 running_acc:0.7445\n",
      " 500 train_loss:0.6430 running_acc:0.7469\n",
      " 529Saving train_loss:0.6429 train_acc:0.7478 test_qAUC:0.4915\n",
      "\n",
      "epoch 15 time(m) 28\n",
      " 100 train_loss:0.6431 running_acc:0.7472\n",
      " 200 train_loss:0.6425 running_acc:0.7491\n",
      " 300 train_loss:0.6426 running_acc:0.7489\n",
      " 400 train_loss:0.6424 running_acc:0.7445\n",
      " 500 train_loss:0.6425 running_acc:0.7469\n",
      " 529Saving train_loss:0.6425 train_acc:0.7478 test_qAUC:0.4849\n",
      "\n",
      "epoch 16 time(m) 30\n",
      " 100 train_loss:0.6420 running_acc:0.7472\n",
      " 200 train_loss:0.6420 running_acc:0.7491\n",
      " 300 train_loss:0.6427 running_acc:0.7489\n",
      " 400 train_loss:0.6427 running_acc:0.7445\n",
      " 500 train_loss:0.6426 running_acc:0.7469\n",
      " 529Saving train_loss:0.6426 train_acc:0.7478 test_qAUC:0.4822\n",
      "\n",
      "epoch 17 time(m) 32\n",
      " 100 train_loss:0.6427 running_acc:0.7472\n",
      " 200 train_loss:0.6421 running_acc:0.7491\n",
      " 300 train_loss:0.6423 running_acc:0.7489\n",
      " 400 train_loss:0.6423 running_acc:0.7445\n",
      " 500 train_loss:0.6423 running_acc:0.7469\n",
      " 529Saving train_loss:0.6424 train_acc:0.7478 test_qAUC:0.5011\n",
      "\n",
      "epoch 18 time(m) 34\n",
      " 100 train_loss:0.6428 running_acc:0.7472\n",
      " 200 train_loss:0.6425 running_acc:0.7491\n",
      " 300 train_loss:0.6425 running_acc:0.7489\n",
      " 400 train_loss:0.6419 running_acc:0.7445\n",
      " 500 train_loss:0.6416 running_acc:0.7469\n",
      " 529Saving train_loss:0.6417 train_acc:0.7478 test_qAUC:0.4970\n",
      "\n",
      "epoch 19 time(m) 36\n",
      " 100 train_loss:0.6418 running_acc:0.7472\n",
      " 200 train_loss:0.6421 running_acc:0.7491\n",
      " 300 train_loss:0.6422 running_acc:0.7489\n",
      " 400 train_loss:0.6423 running_acc:0.7445\n",
      " 500 train_loss:0.6423 running_acc:0.7469\n",
      " 529Saving train_loss:0.6423 train_acc:0.7478 test_qAUC:0.4961\n",
      "\n",
      "epoch 20 time(m) 38\n",
      " 100 train_loss:0.6414 running_acc:0.7472\n",
      " 200 train_loss:0.6417 running_acc:0.7491\n",
      " 300 train_loss:0.6415 running_acc:0.7489\n",
      " 400 train_loss:0.6417 running_acc:0.7445\n",
      " 500 train_loss:0.6420 running_acc:0.7469\n",
      " 529Saving train_loss:0.6420 train_acc:0.7478 test_qAUC:0.5069\n",
      "\n",
      "epoch 21 time(m) 40\n",
      " 100 train_loss:0.6419 running_acc:0.7472\n",
      " 200 train_loss:0.6407 running_acc:0.7491\n",
      " 300 train_loss:0.6410 running_acc:0.7489\n",
      " 400 train_loss:0.6413 running_acc:0.7445\n",
      " 500 train_loss:0.6412 running_acc:0.7469\n",
      " 529Saving train_loss:0.6412 train_acc:0.7478 test_qAUC:0.5164\n",
      "\n",
      "epoch 22 time(m) 42\n",
      " 100 train_loss:0.6434 running_acc:0.7472\n",
      " 200 train_loss:0.6417 running_acc:0.7491\n",
      " 300 train_loss:0.6419 running_acc:0.7489\n",
      " 400 train_loss:0.6417 running_acc:0.7445\n",
      " 500 train_loss:0.6422 running_acc:0.7469\n",
      " 529Saving train_loss:0.6421 train_acc:0.7478 test_qAUC:0.5010\n",
      "\n",
      "epoch 23 time(m) 44\n",
      " 100 train_loss:0.6423 running_acc:0.7472\n",
      " 200 train_loss:0.6417 running_acc:0.7491\n",
      " 300 train_loss:0.6421 running_acc:0.7489\n",
      " 400 train_loss:0.6420 running_acc:0.7445\n",
      " 500 train_loss:0.6421 running_acc:0.7469\n",
      " 529Saving train_loss:0.6422 train_acc:0.7478 test_qAUC:0.4993\n",
      "\n",
      "epoch 24 time(m) 46\n",
      " 100 train_loss:0.6423 running_acc:0.7472\n",
      " 200 train_loss:0.6420 running_acc:0.7491\n",
      " 300 train_loss:0.6420 running_acc:0.7489\n",
      " 400 train_loss:0.6422 running_acc:0.7445\n",
      " 500 train_loss:0.6421 running_acc:0.7469\n",
      " 529Saving train_loss:0.6421 train_acc:0.7478 test_qAUC:0.5033\n",
      "\n",
      "epoch 25 time(m) 48\n",
      " 100 train_loss:0.6414 running_acc:0.7472\n",
      " 200 train_loss:0.6407 running_acc:0.7491\n",
      " 300 train_loss:0.6411 running_acc:0.7489\n",
      " 400 train_loss:0.6413 running_acc:0.7445\n",
      " 500 train_loss:0.6413 running_acc:0.7469\n",
      " 529Saving train_loss:0.6412 train_acc:0.7478 test_qAUC:0.5017\n",
      "\n",
      "epoch 26 time(m) 50\n",
      " 100 train_loss:0.6427 running_acc:0.7472\n",
      " 200 train_loss:0.6416 running_acc:0.7491\n",
      " 300 train_loss:0.6415 running_acc:0.7489\n",
      " 400 train_loss:0.6409 running_acc:0.7445\n",
      " 500 train_loss:0.6411 running_acc:0.7469\n",
      " 529Saving train_loss:0.6414 train_acc:0.7478 test_qAUC:0.4905\n",
      "\n",
      "epoch 27 time(m) 51\n",
      " 100 train_loss:0.6414 running_acc:0.7472\n",
      " 200 train_loss:0.6414 running_acc:0.7491\n",
      " 300 train_loss:0.6414 running_acc:0.7489\n",
      " 400 train_loss:0.6414 running_acc:0.7445\n",
      " 500 train_loss:0.6412 running_acc:0.7469\n",
      " 529Saving train_loss:0.6412 train_acc:0.7478 test_qAUC:0.4926\n",
      "\n",
      "epoch 28 time(m) 53\n",
      " 100 train_loss:0.6426 running_acc:0.7472\n",
      " 200 train_loss:0.6408 running_acc:0.7491\n",
      " 283"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "#net = RNNModel()\n",
    "net = CNNModel()\n",
    "#net.init_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam( net.parameters(), lr=0.001, betas=(0.9, 0.99), amsgrad=True, weight_decay = 1e-5)\n",
    "net.train()\n",
    "\n",
    "Task_name = 'CNN'\n",
    "name = 'curve3'\n",
    "# if not os.path.exists('result_'+ Task_name):\n",
    "#     with open(os.path.join('./result_csv','result_'+ Task_name+ '.csv'), 'w') as f:\n",
    "#         info = '_ninput:'+str(ninput)+'_nhid:'+str(nhid)+'_nlayers:'+str(nlayers)\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(['epoch','train_perplexity','train_acc','test_perplexity','test_acc','time(m)',info])\n",
    "# else:\n",
    "#     raise SystemExit('please change Task_name!')\n",
    "since = time.time()\n",
    "best_qAUC = 0.0\n",
    "with open(name+'.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['train_epoch_loss', 'train_epoch_acc', 'test_qAUC'])\n",
    "for epoch in range(1, 200):\n",
    "    code_time = (time.time()-since)/60\n",
    "    print()\n",
    "    print('epoch',epoch, 'time(m)', int(code_time))\n",
    "    best_test_epoch_loss = 10000\n",
    "    net, train_epoch_loss, train_epoch_acc = train(net, data_loader)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        train_model(\"No\",\"sample_test.csv\",\"result.csv\")\n",
    "        qAUC = cal_Auc(\"sample_test.csv\",\"result.csv\")\n",
    "    with open(name+'.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([train_epoch_loss, train_epoch_acc, qAUC])\n",
    "    print('Saving train_loss:{:.4f} train_acc:{:.4f} test_qAUC:{:.4f}'.\n",
    "          format(train_epoch_loss, train_epoch_acc, qAUC))\n",
    "    #model, test_epoch_loss, test_epoch_acc = evaluate(model, data_loader)\n",
    "#     with open(os.path.join('./result_csv','result_'+ Task_name+ '.csv'), 'a') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow([epoch, train_epoch_loss, train_epoch_acc.item(), test_epoch_loss, test_epoch_acc.item(), code_time])\n",
    "    if best_qAUC < qAUC:\n",
    "        best_qAUC = qAUC\n",
    "        torch.save(net, name+'.pkl')\n",
    "        print('model saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "g-gYcjLc7nTC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def train(net, data_loader):\n",
    "    net.train()\n",
    "    data_loader.set_train()\n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    for i in range(1,int(17000/batch_size)-1):\n",
    "        print('\\r',i, end='')\n",
    "        optimizer.zero_grad()\n",
    "        data_input = data_loader.get_data()\n",
    "        output = net(data_input['query'], data_input['title']) # output.shape=[32,2]\n",
    "        _, pred = torch.max(output,1)\n",
    "        #_, pred_top5 = torch.topk(output, 1000, dim=1)\n",
    "        loss = criterion(output, data['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #pdb.set_trace()\n",
    "        running_loss += loss.item() * batch_size\n",
    "        running_acc += torch.sum(pred.data == data_input['label'].data).item()\n",
    "        #epdb.set_trace()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print(' train_loss:{:.4f} running_acc:{:.4f}'.\n",
    "            format(running_loss / (i * batch_size) , running_acc/(i*batch_size)))\n",
    "            \n",
    "    epoch_loss = running_loss / (i * batch_size)\n",
    "    epoch_acc = running_acc / (i * batch_size)\n",
    "    time1 = time.time()-since\n",
    "    #print()\n",
    "    return net, epoch_loss, epoch_acc\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "M4e1AtGwybRe",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "#from memory_profiler import memory_usage, profile\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# 用于填写模型训练代码\n",
    "#@profile\n",
    "def train_model(train_path, test_path, result_path):\n",
    "    with open(test_path, \"r\") as test, open(result_path, \"w\") as result:\n",
    "        test_data = csv.reader(test)\n",
    "        wirter = csv.writer(result)\n",
    "        # wirter.writerow(\"1\")\n",
    "        for row_num, row in enumerate(test_data):\n",
    "            # print(\"%s,%s,%s\" % (row[0], row[2], random.random()))\n",
    "            process_data = []\n",
    "            process_data.append(row[0])\n",
    "            process_data.append(row[2])\n",
    "            net.eval()\n",
    "            query, title, label = data_loader.convert(row)\n",
    "            mypred = net(query, title)\n",
    "            #pdb.set_trace()\n",
    "            mypred = nn.functional.softmax(mypred.squeeze(),dim=0)\n",
    "            #pdb.set_trace()\n",
    "            process_data.append(mypred[1].item())\n",
    "            #pdb.set_trace()\n",
    "            wirter.writerow(process_data)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     time_before = time.time()\n",
    "#     train_model(\"No\",\n",
    "#                 \"sample_test.csv\",\n",
    "#                 \"result.csv\")\n",
    "#     time_aft = time.time()\n",
    "#     print(time_aft - time_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Tq15SKIWylzo",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def cal_Auc(test_path, result_path):\n",
    "    # y_true = [0, 0, 1, 1]\n",
    "    # y_scores = [0.1, 0.4, 0.35, 0.8]\n",
    "    df_test = pd.read_csv(test_path, encoding='utf-8', header=-1)\n",
    "    df_result = pd.read_csv(result_path, encoding='utf-8', header=-1)\n",
    "    query_num = list(set(df_test.iloc[:, 0]))\n",
    "    # print(len(query_num))\n",
    "    query_total = len(query_num)\n",
    "    auc_sum = 0\n",
    "    # columns = df_test.columns.values.tolist()\n",
    "    # print(columns)\n",
    "    # print(df_test[df_test.iloc[:, 0]==2717])\n",
    "    for query in query_num:\n",
    "        one_query_test = list(df_test[df_test.iloc[:, 0] == query].iloc[:, -1])\n",
    "        one_query_result = list(df_result[df_test.iloc[:, 0] == query].iloc[:, -1])\n",
    "        try:\n",
    "            auc_sum += roc_auc_score(one_query_test, one_query_result)\n",
    "            # print(roc_auc_score(one_query_test, one_query_result))\n",
    "        except:\n",
    "            auc_sum += 0.5\n",
    "\n",
    "    score = auc_sum / query_total\n",
    "    return score\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     cal_Auc(\"sample_test.csv\",\n",
    "#             \"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "F61E50BD97564C17B3532833B4F60E1E",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "roc_auc_score([0.1,0.1,0.05],[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6948C2A5E33340C69B3F101433484BDA",
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "b05b3c9c-ae71-4313-a79d-7019e6037d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1140"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-49455127861e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mresult_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_title_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtest_write_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-49455127861e>\u001b[0m in \u001b[0;36mtest_write_result\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mmypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mresult_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_title_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-df8280cd0c68>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in1, in2)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 16 * 16 * 28 * 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# net = CNNModel()\n",
    "# net.eval()\n",
    "# def test_write_result(model):\n",
    "#     data_loader = MyDataloader(model)\n",
    "#     #net = torch.load()\n",
    "#     with open('result_csv.csv','w') as f_result:\n",
    "#         result_writer = csv.writer(f_result)\n",
    "#         with open('/home/kesci/input/bytedance/first-round/test.csv','r') as f:\n",
    "#             lines = csv.reader(f)\n",
    "#             for step, line in enumerate(lines):\n",
    "#                 if step % 10 == 0:\n",
    "#                     print('\\r', step, end='')\n",
    "#                 query_id = line[0]\n",
    "#                 query_title_id = line[2]\n",
    "#                 query = line[1]\n",
    "#                 title = line[3]\n",
    "#                 #pdb.set_trace()\n",
    "#                 query, title, label = data_loader.convert(line)\n",
    "#                 #pdb.set_trace()\n",
    "#                 mypred = net(query, title)\n",
    "#                 #pdb.set_trace()\n",
    "#                 result_writer.writerow([query_id, query_title_id, mypred.data[0,1]])\n",
    "        \n",
    "# test_write_result(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4A29CBB7932C41ED877380AD4606D825",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "# #Task_list = ['CNN']\n",
    "# def myplot(*Task_list):\n",
    "#     plt.figure()\n",
    "#     color_list = ['blue','orange','green']\n",
    "#     for i, task in enumerate(Task_list):\n",
    "#         epoch_list = []\n",
    "#         train_acc_list = []\n",
    "#         valid_acc_list = []\n",
    "#         with open('curve.csv', 'r') as f:\n",
    "#             f_csv = csv.reader(f)\n",
    "#             headers = next(f_csv)\n",
    "#             for row in f_csv:\n",
    "#                 train_loss_list.append(float(row[0]))\n",
    "#                 train_acc_list.append(float(row[1]))\n",
    "#                 valid_qAUC_list.append(float(row[2]))        \n",
    "#         epoch_list = range(0,len(train_acc_list))\n",
    "#         plt.plot(epoch_list,train_acc_list,'-.',color=color_list[i])\n",
    "#         plt.plot(epoch_list,valid_acc_list,color=color_list[i])\n",
    "#         plt.plot(epoch_list,train_acc_list,'-.',color=color_list[i])\n",
    "#         plt.plot(epoch_list,valid_acc_list,color=color_list[i])   \n",
    "#     plt.xlim([0,100])\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     myfig = plt.gcf()\n",
    "#     myfig.savefig('best_model_new.eps',format='eps',dpi=1000)\n",
    "#     myfig.savefig('best_model_new.png',format='png',dpi=1000)\n",
    "#     plt.show()\n",
    "\n",
    "# f_csv = myplot('CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "3D8DAF7D423A4D0BAA8304E2B254324E",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284.0
    },
    "outputId": "d33b6f2d-b4db-4969-9bb9-f19fd0fbe6a1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkigmACIiiWICICKSKCYAIiKJ+j/Mdp4qZ1xmwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "def myplot(*Task_list):\n",
    "    plt.figure(facecolor='w')\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valid_qAUC_list = []\n",
    "    with open(name+'.csv', 'r') as f:\n",
    "        f_csv = csv.reader(f)\n",
    "        headers = next(f_csv)\n",
    "        for row in f_csv:\n",
    "            train_loss_list.append(float(row[0]))\n",
    "            train_acc_list.append(float(row[1]))\n",
    "            valid_qAUC_list.append(float(row[2]))        \n",
    "        epoch_list = range(0,len(train_acc_list))\n",
    "    plt.plot(epoch_list,train_loss_list)\n",
    "    plt.plot(epoch_list,train_acc_list)\n",
    "    plt.plot(epoch_list,valid_qAUC_list)\n",
    "    plt.legend(['train_loss','train_acc','valid_qAUC'])\n",
    "          \n",
    "    plt.xlim([0,50])\n",
    "    plt.ylim([0.4,0.8])\n",
    "    plt.xlabel('Epoch')\n",
    "    #plt.ylabel('Accuracy')\n",
    "    myfig = plt.gcf()\n",
    "    myfig.savefig(name+'.eps',format='eps',dpi=500)\n",
    "    myfig.savefig(name+'.png',format='png',dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "f_csv = myplot('CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfGNFqIlSEdq",
    "colab_type": "text"
   },
   "source": [
    "## 线下测试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "DE2FAB783880492A9FB3422D32992B55",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# 分割CSV\n",
    "import csv\n",
    "def sample_div(input_path, output1_path, output2_path):\n",
    "    with open(input_path, \"r\") as input, open(output1_path, \"w\") as output1, open(output2_path, \"w\") as output2:\n",
    "        input_data = csv.reader(input)\n",
    "        writer = csv.writer(output1)\n",
    "        writer2 = csv.writer(output2)\n",
    "        for row_num, row in enumerate(input_data):\n",
    "            if row_num < 17000:\n",
    "                writer.writerow(row)\n",
    "            else:\n",
    "                writer2.writerow(row)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sample_div(\"train_data.sample\",\n",
    "               \"sample_train.csv\",\n",
    "               \"sample_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5B5D09C96C154FEB833CE70C9296C879",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5DD8BADC0469491187B3EF9B577C97A2",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "id": "57F640D5F5134D968CC9A5B9E3A19641",
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "1006c713-6384-44d6-fb1b-9ba43ec50a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytedance\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "!ls /home/kesci/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "id": "0FC8837CE76942FD8E26C80DECA222DE",
    "scrolled": false,
    "colab_type": "code",
    "colab": {},
    "outputId": "30dc0838-f8bc-4be9-aa67-358ad8d3ddb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lost+found\r\n"
     ]
    }
   ],
   "source": [
    "# 查看个人持久化工作区文件\n",
    "!ls /home/kesci/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "id": "3AA2722709094612903F66D0B7359790",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# 查看当前kernerl下的package\n",
    "!pip list --format=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "id": "50E72C4847F74FE5B9285933586C66B2",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# 显示cell运行时长\n",
    "%load_ext klab-autotime"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2019 大数据挑战赛—mzq (2).ipynb",
   "version": "0.3.2",
   "provenance": []
  },
  "language_info": {
   "name": "python",
   "version": "3.6.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
